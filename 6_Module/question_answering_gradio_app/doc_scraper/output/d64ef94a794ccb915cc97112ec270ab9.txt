PEFT
	
ðŸ¤— PEFT, or Parameter-Efficient Fine-Tuning (PEFT), is a library for efficiently adapting pre-trained language models (PLMs) to various downstream applications without fine-tuning all the modelâ€™s parameters.
PEFT methods only fine-tune a small number of (extra) model parameters, significantly decreasing computational and storage costs because fine-tuning large-scale PLMs is prohibitively costly.
Recent state-of-the-art PEFT techniques achieve performance comparable to that of full fine-tuning.
PEFT is seamlessly integrated with ðŸ¤— Accelerate for large-scale models leveraging DeepSpeed and Big Model Inference.
Get started
Start here if you're new to ðŸ¤— PEFT to get an overview of the library's main features, and how to train a model with a PEFT method.
How-to guides
Practical guides demonstrating how to apply various PEFT methods across different types of tasks like image classification, causal language modeling, automatic speech recognition, and more. Learn how to use ðŸ¤— PEFT with the DeepSpeed and Fully Sharded Data Parallel scripts.
Conceptual guides
Get a better theoretical understanding of how LoRA and various soft prompting methods help reduce the number of trainable parameters to make training more efficient.
Reference
Technical descriptions of how ðŸ¤— PEFT classes and methods work.

Supported methods
	
LoRA: LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS
Prefix Tuning: Prefix-Tuning: Optimizing Continuous Prompts for Generation, P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks
P-Tuning: GPT Understands, Too
Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning
AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning
LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention
IA3: Infused Adapter by Inhibiting and Amplifying Inner Activations

Supported models
	
The tables provided below list the PEFT methods and models supported for each task. To apply a particular PEFT method for
a task, please refer to the corresponding Task guides.

Causal Language Modeling
	
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3
GPT-2
âœ…
âœ…
âœ…
âœ…
âœ…
Bloom
âœ…
âœ…
âœ…
âœ…
âœ…
OPT
âœ…
âœ…
âœ…
âœ…
âœ…
GPT-Neo
âœ…
âœ…
âœ…
âœ…
âœ…
GPT-J
âœ…
âœ…
âœ…
âœ…
âœ…
GPT-NeoX-20B
âœ…
âœ…
âœ…
âœ…
âœ…
LLaMA
âœ…
âœ…
âœ…
âœ…
âœ…
ChatGLM
âœ…
âœ…
âœ…
âœ…
âœ…

Conditional Generation
	
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3
T5
âœ…
âœ…
âœ…
âœ…
âœ…
BART
âœ…
âœ…
âœ…
âœ…
âœ…

Sequence Classification
	
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3
BERT
âœ…
âœ…
âœ…
âœ…
âœ…
RoBERTa
âœ…
âœ…
âœ…
âœ…
âœ…
GPT-2
âœ…
âœ…
âœ…
âœ…

Bloom
âœ…
âœ…
âœ…
âœ…

OPT
âœ…
âœ…
âœ…
âœ…

GPT-Neo
âœ…
âœ…
âœ…
âœ…

GPT-J
âœ…
âœ…
âœ…
âœ…

Deberta
âœ…

âœ…
âœ…

Deberta-v2
âœ…

âœ…
âœ…


Token Classification
	
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3
BERT
âœ…
âœ…



RoBERTa
âœ…
âœ…



GPT-2
âœ…
âœ…



Bloom
âœ…
âœ…



OPT
âœ…
âœ…



GPT-Neo
âœ…
âœ…



GPT-J
âœ…
âœ…



Deberta
âœ…




Deberta-v2
âœ…





Text-to-Image Generation
	
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3
Stable Diffusion
âœ…





Image Classification
	
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3

ViT
âœ…





Swin
âœ…






Image to text (Multi-modal models)
	
We have tested LoRA for ViT and Swin for fine-tuning on image classification.
However, it should be possible to use LoRA for any ViT-based model from ðŸ¤— Transformers.
Check out the Image classification task guide to learn more. If you run into problems, please open an issue.
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3
Blip-2
âœ…





Semantic Segmentation
	
As with image-to-text models, you should be able to apply LoRA to any of the segmentation models.
Itâ€™s worth noting that we havenâ€™t tested this with every architecture yet. Therefore, if you come across any issues, kindly create an issue report.
Model
LoRA
Prefix Tuning
P-Tuning
Prompt Tuning
IA3
SegFormer
âœ…
